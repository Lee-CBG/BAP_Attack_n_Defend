{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import sys, os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epi</th>\n",
       "      <th>tcr</th>\n",
       "      <th>binding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAAGIGILTV</td>\n",
       "      <td>CASSLGNEQF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EAAGIGILTV</td>\n",
       "      <td>CASSLGVATGELF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EAAGIGILTV</td>\n",
       "      <td>CASSQEEGGGSWGNTIYF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAAGIGILTV</td>\n",
       "      <td>CASSQEGLAGASQYF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAAGIGILTV</td>\n",
       "      <td>CASSQETDIVFNOPQHF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          epi                 tcr  binding\n",
       "0  EAAGIGILTV          CASSLGNEQF        1\n",
       "1  EAAGIGILTV       CASSLGVATGELF        1\n",
       "2  EAAGIGILTV  CASSQEEGGGSWGNTIYF        1\n",
       "3  EAAGIGILTV     CASSQEGLAGASQYF        1\n",
       "4  EAAGIGILTV   CASSQETDIVFNOPQHF        1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = pd.read_csv('./data/combined_dataset_repTCRs.csv')\n",
    "contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tcr and epitope sets\n",
    "tcr_set = contents['tcr'].unique()\n",
    "epi_set = contents['epi'].unique()\n",
    "tcr_rank = np.arange(2, len(tcr_set)+2)\n",
    "epi_rank = np.arange(3, len(epi_set)+3)\n",
    "tcr_pd = pd.DataFrame({\"tcr_set\": tcr_set, \"tcr_rank\": tcr_rank})\n",
    "epi_pd = pd.DataFrame({\"epi_set\": epi_set, \"epi_rank\": epi_rank})\n",
    "tcr_pd.to_csv('./data/tcr.csv', index=False, header=False, sep='\\t')\n",
    "epi_pd.to_csv('./data/epitopes.csv', index=False, header=False, sep='\\t')\n",
    "training_set = pd.read_csv('./data/combined_dataset_repTCRs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_split(x_pep, x_tcr, args):\n",
    "\n",
    "    split_type = args.split\n",
    "    idx_test_remove = None\n",
    "    idx_test = None\n",
    "    idx_train = None\n",
    "\n",
    "    if split_type == 'random':\n",
    "        n_total = len(x_pep)\n",
    "    elif split_type == 'epitope':\n",
    "        unique_peptides = np.unique(x_pep)\n",
    "        n_total = len(unique_peptides)\n",
    "    elif split_type == 'tcr':\n",
    "        unique_tcrs = np.unique(x_tcr)\n",
    "        n_total = len(unique_tcrs)\n",
    "\n",
    "    indexfile = re.sub('.csv', f'_{split_type}_data_shuffle.txt', args.infile)\n",
    "    idx_shuffled = np.loadtxt(indexfile, dtype=np.int32)\n",
    "\n",
    "    # Determine data split from folds\n",
    "    n_test = int(round(n_total / args.n_fold))\n",
    "    n_train = n_total - n_test\n",
    "\n",
    "    # Determine position of current test fold\n",
    "    test_fold_start_index = args.idx_test_fold * n_test\n",
    "    test_fold_end_index = (args.idx_test_fold + 1) * n_test\n",
    "\n",
    "    if split_type == 'random':\n",
    "        # Split data evenly among evenly spaced folds\n",
    "        # Determine if there is an outer testing fold\n",
    "        if args.idx_val_fold < 0:\n",
    "            idx_test = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            idx_train = list(set(idx_shuffled).difference(set(idx_test)))\n",
    "        else:\n",
    "            validation_fold_start_index = args.idx_val_fold * n_test\n",
    "            validation_fold_end_index = (args.idx_val_fold + 1) * n_test\n",
    "            idx_test_remove = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            idx_test = idx_shuffled[validation_fold_start_index:validation_fold_end_index]\n",
    "            idx_train = list(set(idx_shuffled).difference(set(idx_test)).difference(set(idx_test_remove)))\n",
    "    elif split_type == 'epitope':\n",
    "        if args.idx_val_fold < 0:\n",
    "            idx_test_pep = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_peptides = unique_peptides[idx_test_pep]\n",
    "            idx_test = [index for index, pep in tqdm(enumerate(x_pep)) if pep in test_peptides]\n",
    "            idx_train = list(set(range(len(x_pep))).difference(set(idx_test)))\n",
    "        else:\n",
    "            validation_fold_start_index = args.idx_val_fold * n_test\n",
    "            validation_fold_end_index = (args.idx_val_fold + 1) * n_test\n",
    "            idx_test_remove_pep = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_remove_peptides = unique_peptides[idx_test_remove_pep]\n",
    "            idx_test_pep = idx_shuffled[validation_fold_start_index:validation_fold_end_index]\n",
    "            test_peptides = unique_peptides[idx_test_pep]\n",
    "            idx_test = [index for index, pep in tqdm(enumerate(x_pep)) if pep in test_peptides]\n",
    "            idx_test_remove = [index for index, pep in enumerate(x_pep) if pep in test_remove_peptides]\n",
    "            idx_train = list(set(range(len(x_pep))).difference(set(idx_test)).difference(set(idx_test_remove)))\n",
    "    elif split_type == 'tcr':\n",
    "        if args.idx_val_fold < 0:\n",
    "            idx_test_tcr = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_tcrs = unique_tcrs[idx_test_tcr]\n",
    "            idx_test = [index for index, tcr in tqdm(enumerate(x_tcr)) if tcr in test_tcrs]\n",
    "            idx_train = list(set(range(len(x_tcr))).difference(set(idx_test)))\n",
    "        else:\n",
    "            validation_fold_start_index = args.idx_val_fold * n_test\n",
    "            validation_fold_end_index = (args.idx_val_fold + 1) * n_test\n",
    "            idx_test_remove_tcr = idx_shuffled[test_fold_start_index:test_fold_end_index]\n",
    "            test_remove_tcrs = unique_tcrs[idx_test_remove_tcr]\n",
    "            idx_test_tcr = idx_shuffled[validation_fold_start_index:validation_fold_end_index]\n",
    "            test_tcrs = unique_tcrs[idx_test_tcr]\n",
    "            idx_test = [index for index, tcr in tqdm(enumerate(x_tcr)) if tcr in test_tcrs]\n",
    "            idx_test_remove = [index for index, tcr in enumerate(x_tcr) if tcr in test_remove_tcrs]\n",
    "            idx_train = list(set(range(len(x_tcr))).difference(set(idx_test)).difference(set(idx_test_remove)))\n",
    "\n",
    "    return idx_train, idx_test, idx_test_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c91f0e9674b4b70be38458ddb241a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./data/combined_dataset_repTCRs_tcr_data_shuffle.txt', 'r') as f:\n",
    "\tlines_tcr = f.readlines()\n",
    "lines_tcr = [int(l.rstrip('\\n')) for l in lines_tcr]\n",
    "train_tcr = np.array(lines_tcr)\n",
    "test_tcr = np.array(set(np.arange(len(training_set))) - set(train_tcr))\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    split: str = 'tcr'\n",
    "    infile = str = './data/combined_dataset_repTCRs.csv'\n",
    "    n_fold: int = 5\n",
    "    idx_test_fold: int = 0\n",
    "    idx_val_fold: int = -1\n",
    "\n",
    "id_train_tcr, id_test_tcr, id_test_rmv_tcr = load_data_split(training_set['epi'], training_set['tcr'], Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tcr = training_set.iloc[id_train_tcr]\n",
    "test_dataset_tcr = training_set.iloc[id_test_tcr]\n",
    "tcr_readin = pd.read_csv('./data/tcr.csv', header=None, sep='\\t')\n",
    "tcr_dict = dict(zip(tcr_readin[0], tcr_readin[1]))\n",
    "epi_readin = pd.read_csv('./data/epitopes.csv', header=None, sep='\\t')\n",
    "epi_dict = dict(zip(epi_readin[0], epi_readin[1]))\n",
    "\n",
    "train_dataset_tcr_ready = pd.DataFrame({'ligand_name': train_dataset_tcr['epi'].map(epi_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'sequence_id': train_dataset_tcr['tcr'].map(tcr_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'label': train_dataset_tcr['binding']})\n",
    "train_dataset_tcr_ready.reset_index(drop=True, inplace=True)\n",
    "# train_dataset_tcr.loc[:,'tcr_idx'] = train_dataset_tcr['tcr'].map(tcr_dict).fillna(-1)\n",
    "# train_dataset_tcr.loc[:,'epi_idx'] = train_dataset_tcr['epi'].map(epi_dict).fillna(-1)\n",
    "# train_dataset_tcr.loc[:,'idx'] = np.arange(len(train_dataset_tcr))\n",
    "# train_dataset_tcr.set_index('idx', inplace=True)\n",
    "test_dataset_tcr_ready = pd.DataFrame({'ligand_name': test_dataset_tcr['epi'].map(epi_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'sequence_id': test_dataset_tcr['tcr'].map(tcr_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'label': test_dataset_tcr['binding']})\n",
    "test_dataset_tcr_ready.reset_index(drop=True, inplace=True)\n",
    "# test_dataset_tcr_ready.loc[:,'idx'] = np.arange(len(test_dataset_tcr_ready))\n",
    "# test_dataset_tcr_ready.set_index('idx', inplace=True)\n",
    "train_dataset_tcr_ready.to_csv('./data/tcr_train_split.csv', index=True, sep=',')\n",
    "test_dataset_tcr_ready.to_csv('./data/tcr_test_split.csv', index=True, sep=',')\n",
    "# test_dataset_tcr.loc[:,'tcr_idx'] = test_dataset_tcr['tcr'].map(tcr_dict).fillna(-1)\n",
    "# test_dataset_tcr.loc[:,'epi_idx'] = test_dataset_tcr['epi'].map(epi_dict).fillna(-1)\n",
    "# test_dataset_tcr.loc[:,'idx'] = np.arange(len(test_dataset_tcr))\n",
    "# test_dataset_tcr.set_index('idx', inplace=True)\n",
    "\n",
    "# train_csv_tcr = train_dataset_tcr[['epi_idx', 'tcr_idx', 'binding']]\n",
    "# test_csv_tcr = test_dataset_tcr[['epi_idx', 'tcr_idx', 'binding']]\n",
    "# train_csv_tcr.to_csv('./data/tcr_train_split.csv', index=True, header=['ligand_name','sequence_id','label'], sep=',')\n",
    "# test_csv_tcr.to_csv('./data/tcr_test_split.csv', index=True, header=['ligand_name','sequence_id','label'], sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epitope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e24e8824fe4057a6e8d1fe0a9c8400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('./data/combined_dataset_repTCRs_epitope_data_shuffle.txt', 'r') as f:\n",
    "\tlines_epi = f.readlines()\n",
    "lines_epi = [int(l.rstrip('\\n')) for l in lines_epi]\n",
    "train_epi = np.array(lines_epi)\n",
    "train_epi = np.array(set(np.arange(len(training_set))) - set(train_epi))\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    split: str = 'epitope'\n",
    "    infile = str = './data/combined_dataset_repTCRs.csv'\n",
    "    n_fold: int = 5\n",
    "    idx_test_fold: int = 0\n",
    "    idx_val_fold: int = -1\n",
    "\n",
    "id_train_epi, id_test_epi, id_test_rmv_epi = load_data_split(training_set['epi'], training_set['tcr'], Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_epi = training_set.iloc[id_train_epi]\n",
    "test_dataset_epi = training_set.iloc[id_test_epi]\n",
    "epi_readin = pd.read_csv('./data/tcr.csv', header=None, sep='\\t')\n",
    "epi_dict = dict(zip(epi_readin[0], epi_readin[1]))\n",
    "epi_readin = pd.read_csv('./data/epitopes.csv', header=None, sep='\\t')\n",
    "epi_dict = dict(zip(epi_readin[0], epi_readin[1]))\n",
    "\n",
    "# train_dataset_epi.loc[: ,'tcr_idx'] = train_dataset_epi.iloc['tcr'].map(tcr_dict).fillna(-1)\n",
    "# train_dataset_epi.loc[: ,'epi_idx'] = train_dataset_epi.iloc['epi'].map(epi_dict).fillna(-1)\n",
    "# test_dataset_epi.loc[: ,'tcr_idx'] = test_dataset_epi.iloc['tcr'].map(tcr_dict).fillna(-1)\n",
    "# test_dataset_epi.loc[: ,'epi_idx'] = test_dataset_epi.iloc['epi'].map(epi_dict).fillna(-1)\n",
    "# test_dataset_tcr.loc[: ,'idx'] = np.arange(len(test_dataset_tcr))\n",
    "# test_dataset_tcr.set_index('idx', inplace=True)\n",
    "train_dataset_epi_ready = pd.DataFrame({'ligand_name': train_dataset_epi['epi'].map(epi_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'sequence_id': train_dataset_epi['tcr'].map(tcr_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'label': train_dataset_epi['binding']})\n",
    "train_dataset_epi_ready.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_epi_ready = pd.DataFrame({'ligand_name': test_dataset_epi['epi'].map(epi_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'sequence_id': test_dataset_epi['tcr'].map(tcr_dict).fillna(-1),\n",
    "\t\t\t\t\t\t\t\t\t\t'label': test_dataset_epi['binding']})\n",
    "test_dataset_epi_ready.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "train_dataset_epi_ready.to_csv('./data/epi_train_split.csv', index=True, sep=',')\n",
    "test_dataset_epi_ready.to_csv('./data/epi_test_split.csv', index=True, sep=',')\n",
    "# train_csv_epi = train_dataset_epi[['epi_idx', 'tcr_idx', 'binding']]\n",
    "# test_csv_epi = test_dataset_epi[['epi_idx', 'tcr_idx', 'binding']]\n",
    "# train_csv_epi.to_csv('./data/epi_train_split.csv', index=True, header=['ligand_name','sequence_id','label'], sep=',')\n",
    "# test_csv_epi.to_csv('./data/epi_test_split.csv', index=True, header=['ligand_name','sequence_id','label'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_readin = pd.read_csv('./data/tcr.csv', header=None, sep='\\t')\n",
    "tcr_dict = dict(zip(tcr_readin[0], tcr_readin[1]))\n",
    "epi_readin = pd.read_csv('./data/epitopes.csv', header=None, sep='\\t')\n",
    "epi_dict = dict(zip(epi_readin[0], epi_readin[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_dict_rev =  dict(zip(epi_readin[1], epi_readin[0]))\n",
    "tcr_dict_rev =  dict(zip(tcr_readin[1], tcr_readin[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_train_split = pd.read_csv('./data/tcr_train_split.csv', index_col=0)\n",
    "tcr_test_split = pd.read_csv('./data/tcr_test_split.csv', index_col=0)\n",
    "train_pred = {epi_dict_rev[row['ligand_name']]+tcr_dict_rev[row['sequence_id']]: row['label']  for index, row in tcr_train_split.iterrows()}\n",
    "test_pred = {epi_dict_rev[row['ligand_name']]+tcr_dict_rev[row['sequence_id']]: row['label']  for index, row in tcr_test_split.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('./data/combined_dataset_repTCRs.csv')\n",
    "label = {row['epi']+row['tcr']: row['binding']  for index, row in training_set.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300015\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(label):\n",
    "\ttry: \n",
    "\t\tassert label[val] == train_pred[val]\n",
    "\texcept KeyError:\n",
    "\t\ttry:\n",
    "\t\t\tassert label[val] == test_pred[val]\n",
    "\t\texcept KeyError:\n",
    "\t\t\tprint('wrong')\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_train_split = pd.read_csv('./data/epi_train_split.csv', index_col=0)\n",
    "epi_test_split = pd.read_csv('./data/epi_test_split.csv', index_col=0)\n",
    "train_pred = {epi_dict_rev[row['ligand_name']]+tcr_dict_rev[row['sequence_id']]: row['label']  for index, row in epi_train_split.iterrows()}\n",
    "test_pred = {epi_dict_rev[row['ligand_name']]+tcr_dict_rev[row['sequence_id']]: row['label']  for index, row in epi_test_split.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300015\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(label):\n",
    "\ttry: \n",
    "\t\tassert label[val] == train_pred[val]\n",
    "\texcept KeyError:\n",
    "\t\ttry:\n",
    "\t\t\tassert label[val] == test_pred[val]\n",
    "\t\texcept KeyError:\n",
    "\t\t\tprint('wrong')\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr = pd.read_csv('./data/tcr.csv', header=None, sep='\\t')\t\n",
    "tcr[0] = tcr[0].str.upper()\n",
    "tcr.to_csv('./data/tcr.csv', header=None, sep='\\t')\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bap-attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
